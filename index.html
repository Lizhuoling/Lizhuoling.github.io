
<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">

<head>

  <title>Zhuoling Li's Homepage</title>

  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <meta name="description" content="Zhuoling Li is currently pursuing a M.S. degree in Tsinghua University.">
  <meta name="keywords" content="Zhuoling Li, 李卓凌, lizhuoling, Zhuoling, Deep Learning, Tsinghua University, THU, Computer, Vision">
  <meta name="author" content="Zhuoling Li" />

  <link rel="stylesheet" href="w3.css">

  <style>
  .w3-sidebar a {font-family: "Roboto", sans-serif}
  body,h1,h2,h3,h4,h5,h6,.w3-wide {font-family: "Montserrat", sans-serif;}
  </style>

  <link rel="icon" type="image/png" href="images/icon.png">
 
</head>


<body class="w3-content" style="max-width:1000px">

<!-- Sidebar/menu -->
<nav class="w3-sidebar w3-bar-block w3-black w3-collapse w3-top w3-right" style="z-index:3;width:150px" id="mySidebar">
  <div class="w3-container w3-display-container w3-padding-16">
    <h3><b>Zhuoling</b></h3>
  </div>
  <div class="w3-padding-64 w3-text-light-grey w3-large" style="font-weight:bold">
    <a href="#home" class="w3-bar-item w3-button">Home</a>
    <a href="#news" class="w3-bar-item w3-button">News</a>
    <a href="#experience" class="w3-bar-item w3-button">Experience</a>
    <a href="#recent_work" class="w3-bar-item w3-button">Recent Work</a>
    <a href="#publication" class="w3-bar-item w3-button">Publication</a>
  </div>
</nav>

<!-- Top menu on small screens -->
<header class="w3-bar w3-top w3-hide-large w3-black w3-xlarge">
  <div class="w3-bar-item w3-padding-24">Zhuoling</div>
  <a href="javascript:void(0)" class="w3-bar-item w3-button w3-padding-24 w3-right"  style="font-stretch: extra-expanded;" onclick="w3_open()"><b>≡</b></a>
  </div>
</header>

<!-- Overlay effect when opening sidebar on small screens -->
<div class="w3-overlay w3-hide-large" onclick="w3_close()" style="cursor:pointer" title="close side menu" id="myOverlay"></div>

<!-- !PAGE CONTENT! -->
<div class="w3-main" style="margin-left:150px">

  <!-- Push down content on small screens -->
  <div class="w3-hide-large" style="margin-top:83px"></div>

<!-- The Home Section -->
    <div class="w3-container w3-center w3-padding-32" id="home">
      <img style="width: 80%;max-width: 320px" alt="profile photo" src="images/Zhuoling_Circle.png">
      <h1>Zhuoling Li</h1>
        <p class="w3-justify" style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;max-width:600px">
          I am now pursuing the Master degree in <a href="https://www.sigs.tsinghua.edu.cn/">Shenzhen International Graduate School</a>, <a href="https://www.tsinghua.edu.cn/">Tsinghua University</a>, where I work on deep learning and computer vision, etc. Before that, I received the Bachelor degree from <a href="http://aia.hust.edu.cn/">School of Artificial Intelligence and Automation</a>, <a href="https://www.hust.edu.cn/">Huazhong University of Science and Technology</a>. I have published many papers in top conferences and journals, and also served as reviewers for several top conferences.
        </p>
        <p class="w3-center">
          <a href="mailto:lzl20@mails.tsinghua.edu.cn">Email</a> &nbsp/&nbsp
          <a href="https://scholar.google.com/citations?user=2r6ejykAAAAJ">Google Scholar</a>
        </p>
        </tbody></table>
  </div>

<!-- The News Section -->
  <div class="w3-container w3-light-grey w3-padding-32" id="news">
   <h2>News</h2>
	<p><li> 03/2022, One of my papers is selected as an oral presentation of <a href="https://cvpr2022.thecvf.com/">CVPR2022</a>.</li></p>
  	<p><li> 03/2022, Two of my papers have been accepted by <a href="https://cvpr2022.thecvf.com/">CVPR2022</a>.</li></p>
  </div>

<!-- The Experience Section -->
  <div class="w3-container w3-padding-32" id="experience">
   <h2>Experience</h2>
  	<p><li> 09/2016~06/2020, I was pursuing the Bachelor degree in <a href="https://www.hust.edu.cn/">Huazhong University of Science and Technology</a>. During this period, I was advised academically by Prof. <a href="https://scholar.google.com/citations?hl=zh-CN&user=xm_RRHEAAAAJ">Shiping Wen</a> and Prof. <a href="http://faculty.hust.edu.cn/liyuanzheng2/zh_CN/index.htm">Yuanzheng Li</a>. </li></p>
	<p><li> 03/2020~06/2020, I was a full-time intern at the Knowledge Computing Group, <a href="https://www.msra.cn/">Microsoft Research Asia</a>. </li></p>
  	<p><li> 09/2020~Now, I was pursuing the Master degree in <a href="https://www.tsinghua.edu.cn/">Tsinghua University</a>. During this period, I was advised academically by Prof. <a href="https://scholar.google.com/citations?user=eldgnIYAAAAJ">Haoqian Wang</a>. </li></p>
	<p><li> 05/2021~11/2021, I was a full-time intern at the Autonomous Driving Group, <a href="https://www.noahlab.com.hk/">Huawei Noah's Ark Lab</a>. </li></p>
  </div>

<!-- The Recent Work Section -->
  <div class="w3-container w3-padding-32" id="recent_work">
    <h2>Recent Work</h2>
    <p class="w3-justify">
        Recently, I mainly concentrate on the vision perception technique of autonomous driving and robot navigation, especially monocular 3D object detection and tracking.
    </p>

        <h4><li>MonoDDE: The best monocular 3D object detector on KITTI</li></h4>
        <img style="width:96%;" src="images/MonoDDE_pipeline.png">  <br>
        <p class="w3-justify">
	In this work, we focus on the most essential challenge in monocular 3D object detection: how to estimate depth reliably based on only a single 
	image. Through careful analysis, we point out that all existing monocular depth estimation methods are ill-posed and rely on some prior assumptions. 
	These methods would fail if the corresponding assumptions collapse. To solve this problem, we develop a depth solving system that predicts multiple 
	depth values for every object and a depth selection algorithm that selects reliable estimations from all predicted values. Since these values are 
	derived based on different assumptions, the collapse of some assumptions does not fail the final depth estimation. Based on this method, our proposed
	monocular 3D object detector (MonoDDE) ranks 1st on <a href="http://www.cvlibs.net/datasets/kitti/eval_object.php?obj_benchmark=3d">KITTI 3D object detection leaderboard</a>
	when it is submitted (2021.10.18). Outperforming all previous methods by large margins, MonoDDE maintains real-time efficiency (more than 25FPS). This 
	work has been accepted by CVPR2022.
        </p> 

        <h4><li>LT-M3OD: Overcoming long-tailed distribution in 3D object detection</li></h4>
        <img style="width:80%;" src="images/KITTI_LT.png"> <br>
        <p class="w3-justify">
        The long-tailed distribution problem is commonly observed in practical applications of autonomous driving. However, it is hardly studied for 
	monocular 3D object detection. In this work, we study it for the first time. First of all, we conduct extensive experiments to analyze the 
	characteristics of long-tailed monocular 3D object detection. Based on the obtained characteristics, we design several efficient strategies to 
	boost the detection performance of tail classes while retaining the promising accuracy on head classes. The experimental results indicate our 
	method can alleviate the long-tailed distribution problem effectively. For example, evaluated on <a href="http://www.cvlibs.net/datasets/kitti/eval_object.php?obj_benchmark=3d">KITTI</a>, 
	our method boosts the results on Pedestrian and Cyclist for 50.68% and 75.19%, respectively.
        </p> 
  </div>
  
 <!-- The Publications Section -->
  <div class="w3-container w3-padding-32"" id="publication">
    <h2>Publication</h2>
      <p class="w3-left-align" style="line-height:200%">
        I am interested in developing outstanding vision perception models and designing efficient paradigms for training and deploying models. 
      </p>
    <h4> Conference Papers:</h4>

    <ol>
     
      <p>
      <li><strong>Diversity Matters: Fully Exploiting Depth Clues for Reliable Monocular 3D Object Detection</strong>
      <br>
      <strong>Zhuoling Li</strong>, Zhan Qu, Yang Zhou, Jianzhuang Liu, Haoqian Wang, Lihui Jiang. (First author)
      <br>
      2022 | <em>CVPR</em> 2022 | <a style="color: #447ec9" href="papers/MonoDDE_preprint.pdf">paper</a> | <em>Oral</em>
      </p>
										       
      <p>
      <li><strong>Towards Discriminative Representation: Multi-view Trajectory Contrastive Learning for Online Multi-object Tracking</strong>
      <br>
      En Yu, <strong>Zhuoling Li</strong>, Shoudong Han. (Co-First author)
      <br>
      2022 | <em>CVPR</em> 2022 | <a style="color: #447ec9" href="papers/MTrack_preprint.pdf">paper</a>
      </p>
      
     </ol>
     
    <h4> Journal Papers:</h4>
    <ol>
											     
      <p>
      <li><strong>Relationtrack: Relation-aware Multiple Object Tracking with Decoupled Representation</strong>
      <br>
      En Yu, <strong>Zhuoling Li</strong>, Shoudong Han, Hongwei Wang. (Co-First author)
      <br>
      2022 | <em>IEEE Transactions on Multimedia</em> | <a style="color: #447ec9" href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9709649">paper</a>
      </p>	
      
      <p>
      <li><strong>Few-shot Steel Surface Defect Detection</strong>
      <br>
      Haohan Wang, <strong>Zhuoling Li</strong>, Haoqian Wang. (Co-First author)
      <br>
      2021 | <em>IEEE Transactions on Instrumentation and Measurement</em> | <a style="color: #447ec9" href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9709649">paper</a>
      </p>
      
      <p>
      <li><strong>Deep Learning based Densely Connected Network for Load Forecasting</strong>
      <br>
      <strong>Zhuoling Li</strong>, Yuanzheng Li, Yun Liu, Ping Wang, Renzhi Liu, Hoay Beng Gooi. (First author)
      <br>
      2020 | <em>IEEE Transactions on Power Systems</em> | <a style="color: #447ec9" href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9311801">paper</a>
      </p>
      
      <p>
      <li><strong>CLU-CNNs: Object detection for medical images</strong>
      <br>
      <strong>Zhuoling Li</strong>, Minghui Dong, Shiping Wen, Xiang Hu, Pan Zhou, Zhigang Zeng. (First author)
      <br>
      2019 | <em>Neurocomputing</em> | <a style="color: #447ec9" href="https://pdf.sciencedirectassets.com/271597/1-s2.0-S0925231219X0020X/1-s2.0-S0925231219305521/main.pdf?X-Amz-Security-Token=IQoJb3JpZ2luX2VjEBwaCXVzLWVhc3QtMSJIMEYCIQCb5EHPoJh6yRDrVevVOlzvAvP%2BWLXZY%2FVaMWfhHCRk1QIhAOjJo9SiuHRcPv%2FA%2FHtQeXu359J9Mrx3Zna%2BZlXFlOi0KoMECKX%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FwEQBBoMMDU5MDAzNTQ2ODY1Igx62wlURD3RnK1NFQYq1wPxxCA8sQOAjIvW0VbhAZSnrP9fcgz3Nj%2F2Lwu%2F4xeFX%2FbCxVckAellY9UGaz%2FmTnbTFEzq5ALRJtzHF4sPDtcdsDzuFY6xsB0p7%2FkzDsIbPvWTrZdHTUwAX0pbsFrjqZM4GKHijcbxiMxqTZZVYo5rH2jtin9KNemuatfmMZno3wRxn62vZPXOMNl4YHGbbOqhjtG3fY5FydImr1dZIvM0oH6eeec8GpTpidnextcIpwkDCotzRmpVYR8xrYyCtPPBH4Dx8nofH4jUb3V2D8PpjDZb0zPLKzFlWTA5AebzaTO8a7RSEFbgH0lh%2B2GYPRT3H7PlwGBcLtSvfOgpqDdEBoD8orioSH1glSyfANY7b%2ByCwzS346ZESNBZsrEXGz9NpiIsr8ZQGiI90utkYy9y9UGjPhdTIded8My1P8D31bGkON3%2FWdStOuURG74tB6ceFHjGlRaS2K7ZbtU378e8O9%2Bdz89P4LEvjwRz%2FM04Ib%2FTdOX9PYznRSG%2BUDSOznwHzZ8We6dzpfKsjmKfJHsE0%2F4lzK1FcZpHD3iLRJzRChJYGxYfHkNUaltwGfc45tp5lf7lSLamfbWNzaZBJxIIxo7jCFj5lVrh0At403Q6kuvtIz%2BFSSwwo6OBkgY6pAHtZeU1BYsUG4JxdybcUIW1uvzgw0FzMrru58XZqB7aD%2BH1HsvAMMpV4Tzzcd%2FS6zLgmHwRky8HQwsHujfRsonqMNqBCp2fxqa%2Bo6qOJZRAfwobex3tV6cbc6rmmBH6irCh6H%2FIYbatR3MXgVZ3IPJsBnigdrPB5ofnDWCzp6NZqUMFRtYMmQLST0nd%2FfZZb6hY4LXTmRd7QvPe8PkdsRVLuPy5QA%3D%3D&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Date=20220327T122642Z&X-Amz-SignedHeaders=host&X-Amz-Expires=300&X-Amz-Credential=ASIAQ3PHCVTYVVCUP3XI%2F20220327%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Signature=e4ebeddb7db9b0107929d4203beafc382543e1b104f0d231a21ce6f579bf648b&hash=e3ef5969ad5f9e7d252e66daf1fa80fe89af5cf6b0350167e5352858a591c85b&host=68042c943591013ac2b2430a89b270f6af2c76d8dfd086a07176afe7c76c2c61&pii=S0925231219305521&tid=spdf-804b6d5f-a377-43f8-9275-aea20a253c00&sid=b738fb7a77151449b48b8d9322b87f273d70gxrqa&type=client&ua=58045c5b5703010357&rr=6f281dae6f13984f">paper</a>
      </p>
											     
    </ol>

    </p>
  </div>


  <div class="w3-light-grey w3-center w3-padding-24">

  <!-- Default Statcounter code for Yunhe Wang's Homepage
  https://www.wangyunhe.site -->
  No.
  <script type="text/javascript">
  var sc_project=12347113; 
  var sc_invisible=0; 
  var sc_security="21aca5d1"; 
  var sc_https=1; 
  var scJsHost = "https://";
  document.write("<sc"+"ript type='text/javascript' src='" + scJsHost+
  "statcounter.com/counter/counter.js'></"+"script>");
  </script> Visitor Since Feb 2022. Powered by <a href="https://www.w3schools.com/w3css/default.asp" title="W3.CSS" target="_blank" class="w3-hover-opacity">w3.css</a>
  <noscript>
    <div class="statcounter"><a title="Web Analytics Made Easy -
  StatCounter" href="https://statcounter.com/" target="_blank"><img
  class="statcounter" src="https://c.statcounter.com/12347113/0/21aca5d1/0/"
  alt="Web Analytics Made Easy - StatCounter"></a></div>
  </noscript>
  <!-- End of Statcounter Code -->

  </div>

  <!-- End page content -->
</div>

<script>
// Accordion 
function myAccFunc() {
  var x = document.getElementById("demoAcc");
  if (x.className.indexOf("w3-show") == -1) {
    x.className += " w3-show";
  } else {
    x.className = x.className.replace(" w3-show", "");
  }
}

// Click on the "Jeans" link on page load to open the accordion for demo purposes
document.getElementById("myBtn").click();


// Open and close sidebar
function w3_open() {
  document.getElementById("mySidebar").style.display = "block";
  document.getElementById("myOverlay").style.display = "block";
}
 
function w3_close() {
  document.getElementById("mySidebar").style.display = "none";
  document.getElementById("myOverlay").style.display = "none";
}
</script>

</body>
</html>
